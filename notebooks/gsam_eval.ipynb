{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4caba61706c4213a7b97710cf15d219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/tmp/wendler/hf_cache\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add necessary paths for custom modules\n",
    "sys.path.append(\"/share/u/wendler/code/my-sdxl-unbox\")\n",
    "\n",
    "from SDLens import HookedStableDiffusionXLPipeline\n",
    "from SAE import SparseAutoencoder\n",
    "from utils import add_feature_on_area_turbo\n",
    "\n",
    "import supervision as sv\n",
    "import pycocotools.mask as mask_util\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Grounded SAM2 and Grounding DINO imports\n",
    "sys.path.append(\"/share/u/wendler/code/Grounded-SAM-2\")\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from grounding_dino.groundingdino.util.inference import load_model, predict\n",
    "import grounding_dino.groundingdino.datasets.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "n_steps = 4\n",
    "m1 = 1.\n",
    "k_transfer = 5\n",
    "use_down = True\n",
    "use_up = True\n",
    "use_up0 = True\n",
    "use_mid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SDLens/src to sys.path at the top of the scrip\n",
    "\n",
    "# --- Utility functions ---\n",
    "def resize_mask(mask, size=(16, 16)):\n",
    "    return cv2.resize(mask.astype(np.uint8), size, interpolation=cv2.INTER_LANCZOS4) > 0\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple\n",
    "import grounding_dino.groundingdino.datasets.transforms as T\n",
    "\n",
    "def sam_mask(img, prompt, sam2_predictor, grounding_model, BOX_THRESHOLD, TEXT_THRESHOLD):\n",
    "    def load_image(img) -> Tuple[np.array, torch.Tensor]:\n",
    "        transform = T.Compose(\n",
    "            [\n",
    "                T.RandomResize([800], max_size=1333),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        image_source = img.convert(\"RGB\")\n",
    "        image = np.asarray(image_source)\n",
    "        image_transformed, _ = transform(image_source, None)\n",
    "        return image, image_transformed\n",
    "    image_source, image = load_image(img)\n",
    "    sam2_predictor.set_image(image_source)\n",
    "\n",
    "    boxes, confidences, labels = predict(\n",
    "        model=grounding_model,\n",
    "        image=image,\n",
    "        caption=prompt,\n",
    "        box_threshold=BOX_THRESHOLD,\n",
    "        text_threshold=TEXT_THRESHOLD,\n",
    "    )\n",
    "\n",
    "    # process the box prompt for SAM 2\n",
    "    h, w, _ = image_source.shape\n",
    "    boxes = boxes * torch.Tensor([w, h, w, h])\n",
    "    input_boxes = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
    "\n",
    "\n",
    "    # FIXME: figure how does this influence the G-DINO model\n",
    "    # torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "    #if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "        #torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        #torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    masks, scores, logits = sam2_predictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=input_boxes,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    Post-process the output of the model to get the masks, scores, and logits for visualization\n",
    "    \"\"\"\n",
    "    # convert the shape to (n, H, W)\n",
    "    if masks.ndim == 4:\n",
    "        masks = masks.squeeze(1)\n",
    "\n",
    "\n",
    "    confidences = confidences.numpy().tolist()\n",
    "    class_names = labels\n",
    "\n",
    "    class_ids = np.array(list(range(len(class_names))))\n",
    "\n",
    "    labels = [\n",
    "        f\"{class_name} {confidence:.2f}\"\n",
    "        for class_name, confidence\n",
    "        in zip(class_names, confidences)\n",
    "    ]\n",
    "\n",
    "    detections = sv.Detections(\n",
    "        xyxy=input_boxes,  # (n, 4)\n",
    "        mask=masks.astype(bool),  # (n, h, w)\n",
    "        class_id=class_ids\n",
    "    )\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "    annotated_frame = box_annotator.annotate(scene=img.copy(), detections=detections)\n",
    "\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "    mask_annotator = sv.MaskAnnotator()\n",
    "    annotated_frame = mask_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    return detections, labels, annotated_frame\n",
    "    \n",
    "\n",
    "def best_features_saeuron(source_feats, target_feats, k=10):\n",
    "    mean_cat = source_feats.mean(dim=0).mean(dim=0)\n",
    "    mean_dog = target_feats.mean(dim=0).mean(dim=0)\n",
    "    scores = mean_cat/mean_cat.sum() - mean_dog/mean_dog.sum()\n",
    "    arg_sorted = np.argsort(scores.cpu().detach().numpy())\n",
    "    return arg_sorted[::-1][:k].copy(), arg_sorted[:k].copy()\n",
    "    #best_features = np.argsort(scores.cpu().detach().numpy())[::-1][:k].copy()\n",
    "    #return best_features\n",
    "\n",
    "dtype = torch.float16\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pipe = HookedStableDiffusionXLPipeline.from_pretrained(\n",
    "    'stabilityai/sdxl-turbo',\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"balanced\",\n",
    "    variant=(\"fp16\" if dtype==torch.float16 else None)\n",
    ")\n",
    "pipe.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "SAM2_CHECKPOINT = \"/share/u/wendler/code/Grounded-SAM-2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "SAM2_MODEL_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "GROUNDING_DINO_CONFIG = \"/share/u/wendler/code/Grounded-SAM-2/grounding_dino/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "GROUNDING_DINO_CHECKPOINT = \"/share/u/wendler/code/Grounded-SAM-2/gdino_checkpoints/groundingdino_swint_ogc.pth\"\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.25\n",
    "sam2_model = build_sam2(SAM2_MODEL_CONFIG, SAM2_CHECKPOINT, device=device)\n",
    "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "grounding_model = load_model(\n",
    "    model_config_path=GROUNDING_DINO_CONFIG,\n",
    "    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "path_to_checkpoints = '/share/u/wendler/code/my-sdxl-unbox/checkpoints/'\n",
    "code_to_block = {\n",
    "        \"down.2.1\": \"unet.down_blocks.2.attentions.1\",\n",
    "        \"up.0.1\": \"unet.up_blocks.0.attentions.1\",\n",
    "        \"up.0.0\": \"unet.up_blocks.0.attentions.0\",\n",
    "        \"mid.0\": \"unet.mid_block.attentions.0\",\n",
    "    }\n",
    "blocks = list(code_to_block.values())\n",
    "saes = {}\n",
    "k = 10\n",
    "exp = 4\n",
    "for shortcut in code_to_block.keys():\n",
    "    block = code_to_block[shortcut]\n",
    "    sae = SparseAutoencoder.load_from_disk(\n",
    "        os.path.join(path_to_checkpoints, f\"{block}_k{k}_hidden{exp*1280:d}_auxk256_bs4096_lr0.0001\", \"final\")\n",
    "    ).to(device, dtype=dtype)\n",
    "    saes[shortcut] = sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# --- Main experiment ---\n",
    "def add_featuremaps(sae, to_source_features, to_target_features, fmaps, target_mask, module, input, output):\n",
    "        diff = output[0] - input[0]\n",
    "        coefs = sae.encode(diff.permute(0, 2, 3, 1))\n",
    "        mask = torch.zeros([fmaps.shape[0], fmaps.shape[1], fmaps.shape[2], sae.decoder.weight.shape[1]], device=input[0].device)\n",
    "        mask[0,target_mask][..., to_target_features] -= coefs[0, target_mask][..., to_target_features]\n",
    "        mask[..., to_source_features] += fmaps.to(mask.device)\n",
    "        to_add = mask.to(sae.decoder.weight.dtype) @ sae.decoder.weight.T\n",
    "        return (output[0] + to_add.permute(0, 3, 1, 2).to(output[0].device),)\n",
    "    \n",
    "def activation_patching(mean, target_mask, module, input, output):\n",
    "    diff = output[0] - input[0]\n",
    "    diff[0, :, target_mask] += mean[:, None]\n",
    "    return (diff + input[0],)\n",
    "\n",
    "\n",
    "def main(prompt1, prompt2, gsam_prompt1, gsam_prompt2, pipe=pipe, k=10, \n",
    "         blocks_to_intervene=[\"down.2.1\", \"up.0.1\", \"up.0.0\", \"mid.0\"],\n",
    "         n_steps=1, m1=2., k_transfer=10, stat=\"max\", mode=\"sae\", verbose=False,\n",
    "         sam_predictor=sam2_predictor, grounding_model=grounding_model, saes=saes, \n",
    "         result_name=None):\n",
    "    import logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if verbose:\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "    else:\n",
    "        logger.setLevel(logging.INFO)    \n",
    "\n",
    "    logger.debug(\"[4/9] Generating images and caching activations...\")\n",
    "    seed = 42\n",
    "    base_imgs1, cache1 = pipe.run_with_cache(\n",
    "        prompt1,\n",
    "        positions_to_cache=blocks,\n",
    "        num_inference_steps=n_steps,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(device='cpu').manual_seed(seed),\n",
    "        save_input=True,\n",
    "    )\n",
    "    base_imgs2, cache2 = pipe.run_with_cache(\n",
    "        prompt2,\n",
    "        positions_to_cache=blocks,\n",
    "        num_inference_steps=n_steps,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(device='cpu').manual_seed(seed),\n",
    "        save_input=True,\n",
    "    )\n",
    "    img1 = base_imgs1[0][0]\n",
    "    img2 = base_imgs2[0][0]\n",
    "\n",
    "    logger.debug(\"[5/9] Running Grounded SAM on generated images...\")\n",
    "    if gsam_prompt1 == \"background\":\n",
    "        mask1 = np.ones((16, 16), dtype=bool)\n",
    "    else:\n",
    "        detections1, labels1, annotated_frame1 = sam_mask(img1, gsam_prompt1, sam2_predictor, grounding_model, BOX_THRESHOLD, TEXT_THRESHOLD)\n",
    "        masks = [resize_mask(bigmask).astype(np.float32) for bigmask in detections1.mask]\n",
    "        mask1 = np.stack(masks, axis=0).sum(axis=0).astype(bool)\n",
    "    if gsam_prompt2 == \"background\":\n",
    "        mask2 = np.ones((16, 16), dtype=bool)\n",
    "    else:\n",
    "        detections2, labels2, annotated_frame2 = sam_mask(img2, gsam_prompt2, sam2_predictor, grounding_model, BOX_THRESHOLD, TEXT_THRESHOLD)\n",
    "        masks = [resize_mask(bigmask).astype(np.float32) for bigmask in detections2.mask]\n",
    "        mask2 = np.stack(masks, axis=0).sum(axis=0).astype(bool)\n",
    "    if mask1.sum() == 0:\n",
    "        mask1 = np.ones((16, 16), dtype=bool)\n",
    "    if mask2.sum() == 0:\n",
    "        mask2 = np.ones((16, 16), dtype=bool)\n",
    "    logger.debug(\"[6/9] Extracting latents and encoding features...\")\n",
    "    interventions = {}\n",
    "    for shortcut in blocks_to_intervene:\n",
    "        block = code_to_block[shortcut]\n",
    "        diff1 = cache1['output'][block][0] - cache1['input'][block][0]\n",
    "        diff2 = cache2['output'][block][0] - cache2['input'][block][0]\n",
    "        source = diff1[:, :, mask1]\n",
    "        target = diff2[:, :, mask2]\n",
    "        sae = saes[shortcut]\n",
    "        source_feats = sae.encode(source.permute(0, 2, 1))\n",
    "        target_feats = sae.encode(target.permute(0, 2, 1))\n",
    "\n",
    "        logger.debug(\"[7/9] Selecting best features...\")\n",
    "        k = sae.k\n",
    "        to_source_features, to_target_features = best_features_saeuron(source_feats, target_feats, k=k_transfer)\n",
    "        logger.debug(f\"Source features shape: {source_feats.shape}\")\n",
    "        # 1 x 39 x 5120\n",
    "        if verbose:\n",
    "            # make a nice plot with one histogram per feature\n",
    "            fig, axs = plt.subplots(1, len(to_source_features), figsize=(15, 5))\n",
    "            for i, feature in enumerate(to_source_features):\n",
    "                axs[i].hist(source_feats[0][:, feature].cpu().detach().numpy(), bins=\"rice\", edgecolor='black')\n",
    "                axs[i].set_title(f\"Feature {feature}\")\n",
    "                axs[i].set_xlabel(\"Value\")\n",
    "                axs[i].set_ylabel(\"Frequency\")\n",
    "            plt.show()\n",
    "\n",
    "            all_source_feats = sae.encode(diff1.permute(0, 2, 3, 1))\n",
    "            # visualize the feature activation maps of the to_cat_features\n",
    "            plt.imshow(mask1.astype(np.float32))\n",
    "            plt.show()\n",
    "            fig, axs = plt.subplots(1, len(to_source_features), figsize=(15, 5))\n",
    "            for i, feature in enumerate(to_source_features):\n",
    "                axs[i].imshow(mask1.astype(np.float32)*all_source_feats[0, :,:, feature].cpu().detach().numpy())\n",
    "                axs[i].set_title(f\"Feature {feature}\")\n",
    "            plt.show()\n",
    "\n",
    "            fig, axs = plt.subplots(1, len(to_source_features), figsize=(15, 5))\n",
    "            for i, feature in enumerate(to_source_features):\n",
    "                axs[i].imshow((1 - mask1.astype(np.float32))*all_source_feats[0, :,:, feature].cpu().detach().numpy())\n",
    "                axs[i].set_title(f\"Feature {feature}\")\n",
    "            plt.show()\n",
    "            logger.debug(f\"source_feats shape: {source_feats[0].shape}\")\n",
    "        # use max\n",
    "        if stat == \"max\":\n",
    "            stat1_val = source_feats.max(dim=0)[0].max(dim=0)[0][to_source_features]\n",
    "        elif stat == \"mean\":\n",
    "            mymeans = []\n",
    "            logger.debug(f\"source_feats shape: {source_feats.shape}\")\n",
    "            stat1_val = source_feats[source_feats[:, :] > 1e-3].mean(dim=0).mean(dim=0)\n",
    "            #for fidx in to_source_features:\n",
    "            #    coefs = source_feats[0][..., fidx]\n",
    "            #    mymeans.append(coefs[coefs > 1e-3].mean())\n",
    "            #stat1_val = torch.tensor(mymeans, device=torch.device(\"cuda\"))\n",
    "        else:\n",
    "            ValueError(f\"stat1 {stat} not recognized. Choose from: max, mean\")\n",
    "        logger.debug(f\"mean_vals (max): {stat1_val}\")\n",
    "        logger.debug(\"[8/9] Preparing featuremaps for transfer...\")\n",
    "        fmaps = torch.zeros((1, 16, 16, len(to_source_features)), device=device)\n",
    "        fmaps[:, mask2] += (m1*stat1_val).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "        logger.debug(\"[9/9] Running SDXL with feature injection...\")\n",
    "\n",
    "\n",
    "        logger.debug(f\"Decoder weight shape: {sae.decoder.weight.shape}\")\n",
    "        logger.debug(f\"Using mode: {mode}\")\n",
    "        if mode == \"patch_max\":\n",
    "            logger.debug(f\"Cat shape: {source.shape}\")\n",
    "            f = partial(activation_patching, m1*(source[0].max(dim=1)[0] - target[0].max(dim=1)[0]), mask2)\n",
    "            interventions[block] = f\n",
    "        elif mode == \"patch_mean\":\n",
    "            f = partial(activation_patching, m1*(source[0].mean(dim=1) - target[0].mean(dim=1)), mask2)\n",
    "            interventions[block] = f\n",
    "        else:\n",
    "            f = partial(add_featuremaps, sae, to_source_features, to_target_features, fmaps, mask2)\n",
    "            interventions[block] = f\n",
    "\n",
    "    result = pipe.run_with_hooks(\n",
    "        prompt2,\n",
    "        position_hook_dict=interventions,\n",
    "        num_inference_steps=n_steps,\n",
    "        guidance_scale=0.0,\n",
    "        generator=torch.Generator(device='cpu').manual_seed(seed)\n",
    "    ).images[0]\n",
    "\n",
    "    # make a result figure that shows the images with masks and the intervened image\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Image 1 with mask from prompt 1\n",
    "    if gsam_prompt1 != \"background\":\n",
    "        axs[0].imshow(annotated_frame1)\n",
    "    else:\n",
    "        axs[0].imshow(img1)\n",
    "    axs[0].set_title(f\"{prompt1}\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Image 2 with mask from prompt 2\n",
    "    if gsam_prompt2 != \"background\":\n",
    "        axs[1].imshow(annotated_frame2)\n",
    "    else:\n",
    "        axs[1].imshow(img2)\n",
    "    axs[1].set_title(f\"{prompt2}\")\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Intervened result image\n",
    "    axs[2].imshow(result)\n",
    "    axs[2].axis('off')\n",
    "    # tight\n",
    "    #plt.tight_layout()\n",
    "    if result_name is not None:\n",
    "        plt.savefig(result_name + \"_summary.png\")\n",
    "        plt.close()\n",
    "        # save the images\n",
    "        img1.save(result_name + f\"_{gsam_prompt2}_img1.png\")\n",
    "        img2.save(result_name + f\"_{gsam_prompt1}_img2.png\")\n",
    "        result.save(result_name + \".png\")\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000000000000', '000000000001', '000000000002', '000000000003', '000000000004', '000000000005', '000000000006', '000000000007', '000000000008', '000000000009', '000000000010', '000000000011', '000000000012', '000000000013', '000000000014', '000000000015', '000000000016', '000000000017', '000000000018', '000000000019', '000000000020', '000000000021', '000000000022', '000000000023', '000000000024', '000000000025', '000000000026', '000000000027', '000000000028', '000000000029', '000000000030', '000000000031', '000000000032', '000000000033', '000000000034', '000000000035', '000000000036', '000000000037', '000000000038', '000000000039', '000000000040', '000000000041', '000000000042', '000000000043', '000000000044', '000000000045', '000000000046', '000000000047', '000000000048', '000000000049', '000000000050', '000000000051', '000000000052', '000000000053', '000000000054', '000000000055', '000000000056', '000000000057', '000000000058', '000000000059', '000000000060', '000000000061', '000000000062', '000000000063', '000000000064', '000000000065', '000000000066', '000000000067', '000000000068', '000000000069', '000000000070', '000000000071', '000000000072', '000000000073', '000000000074', '000000000075', '000000000076', '000000000077', '000000000078', '000000000079', '000000000080', '000000000081', '000000000082', '000000000083', '000000000084', '000000000085', '000000000086', '000000000087', '000000000088', '000000000089', '000000000090', '000000000091', '000000000092', '000000000093', '000000000094', '000000000095', '000000000096', '000000000097', '000000000098', '000000000099', '000000000100', '000000000101', '000000000102', '000000000103', '000000000104', '000000000105', '000000000106', '000000000107', '000000000108', '000000000109', '000000000110', '000000000111', '000000000112', '000000000113', '000000000114', '000000000115', '000000000116', '000000000117', '000000000118', '000000000119', '000000000120', '000000000121', '000000000122', '000000000123', '000000000124', '000000000125', '000000000126', '000000000127', '000000000128', '000000000129', '000000000130', '000000000131', '000000000132', '000000000133', '000000000134', '000000000135', '000000000136', '000000000137', '000000000138', '000000000139', '111000000000', '111000000001', '111000000002', '111000000003', '111000000004', '111000000005', '111000000006', '111000000007', '111000000008', '111000000009', '112000000000', '112000000001', '112000000002', '112000000003', '112000000004', '112000000005', '112000000006', '112000000007', '112000000008', '112000000009', '113000000000', '113000000001', '113000000002', '113000000003', '113000000004', '113000000005', '113000000006', '113000000007', '113000000008', '113000000009', '114000000000', '114000000001', '114000000002', '114000000003', '114000000004', '114000000005', '114000000006', '114000000007', '114000000008', '114000000009', '121000000000', '121000000001', '121000000002', '121000000003', '121000000004', '121000000005', '121000000006', '121000000007', '121000000008', '121000000009', '122000000000', '122000000001', '122000000002', '122000000003', '122000000004', '122000000005', '122000000006', '122000000007', '122000000008', '122000000009', '123000000000', '123000000001', '123000000002', '123000000003', '123000000004', '123000000005', '123000000006', '123000000007', '123000000008', '123000000009', '124000000000', '124000000001', '124000000002', '124000000003', '124000000004', '124000000005', '124000000006', '124000000007', '124000000008', '124000000009', '211000000000', '211000000001', '211000000002', '211000000003', '211000000004', '211000000005', '211000000006', '211000000007', '211000000008', '211000000009', '212000000000', '212000000001', '212000000002', '212000000003', '212000000004', '212000000005', '212000000006', '212000000007', '212000000008', '212000000009', '213000000000', '213000000001', '213000000002', '213000000003', '213000000004', '213000000005', '213000000006', '213000000007', '213000000008', '213000000009', '214000000000', '214000000001', '214000000002', '214000000003', '214000000004', '214000000005', '214000000006', '214000000007', '214000000008', '214000000009', '221000000000', '221000000001', '221000000002', '221000000003', '221000000004', '221000000005', '221000000006', '221000000007', '221000000008', '221000000009', '222000000000', '222000000001', '222000000002', '222000000003', '222000000004', '222000000005', '222000000006', '222000000007', '222000000008', '222000000009', '223000000000', '223000000001', '223000000002', '223000000003', '223000000004', '223000000005', '223000000006', '223000000007', '223000000008', '223000000009', '224000000000', '224000000001', '224000000002', '224000000003', '224000000004', '224000000005', '224000000006', '224000000007', '224000000008', '224000000009', '311000000000', '311000000001', '311000000002', '311000000003', '311000000004', '311000000005', '311000000006', '311000000007', '311000000008', '311000000009', '312000000000', '312000000001', '312000000002', '312000000003', '312000000004', '312000000005', '312000000006', '312000000007', '312000000008', '312000000009', '313000000000', '313000000001', '313000000002', '313000000003', '313000000004', '313000000005', '313000000006', '313000000007', '313000000008', '313000000009', '314000000000', '314000000001', '314000000002', '314000000003', '314000000004', '314000000005', '314000000006', '314000000007', '314000000008', '314000000009', '321000000000', '321000000001', '321000000002', '321000000003', '321000000004', '321000000005', '321000000006', '321000000007', '321000000008', '321000000009', '322000000000', '322000000001', '322000000002', '322000000003', '322000000004', '322000000005', '322000000006', '322000000007', '322000000008', '322000000009', '323000000000', '323000000001', '323000000002', '323000000003', '323000000004', '323000000005', '323000000006', '323000000007', '323000000008', '323000000009', '324000000000', '324000000001', '324000000002', '324000000003', '324000000004', '324000000005', '324000000006', '324000000007', '324000000008', '324000000009', '411000000000', '411000000001', '411000000002', '411000000003', '411000000004', '412000000000', '412000000001', '412000000002', '412000000003', '412000000004', '413000000000', '413000000001', '413000000002', '413000000003', '413000000004', '414000000000', '414000000001', '414000000002', '414000000003', '414000000004', '421000000000', '421000000001', '421000000002', '421000000003', '421000000004', '422000000000', '422000000001', '422000000002', '422000000003', '422000000004', '423000000000', '423000000001', '423000000002', '423000000003', '423000000004', '424000000000', '424000000001', '424000000002', '424000000003', '424000000004', '511000000000', '511000000001', '511000000002', '511000000003', '511000000004', '512000000000', '512000000001', '512000000002', '512000000003', '512000000004', '513000000000', '513000000001', '513000000002', '513000000003', '513000000004', '514000000000', '514000000001', '514000000002', '514000000003', '514000000004', '521000000000', '521000000001', '521000000002', '521000000003', '521000000004', '522000000000', '522000000001', '522000000002', '522000000003', '522000000004', '523000000000', '523000000001', '523000000002', '523000000003', '523000000004', '524000000000', '524000000001', '524000000002', '524000000003', '524000000004', '611000000000', '611000000001', '611000000002', '611000000003', '611000000004', '612000000000', '612000000001', '612000000002', '612000000003', '612000000004', '613000000000', '613000000001', '613000000002', '613000000003', '613000000004', '614000000000', '614000000001', '614000000002', '614000000003', '614000000004', '621000000000', '621000000001', '621000000002', '621000000003', '621000000004', '622000000000', '622000000001', '622000000002', '622000000003', '622000000004', '623000000000', '623000000001', '623000000002', '623000000003', '623000000004', '624000000000', '624000000001', '624000000002', '624000000003', '624000000004', '711000000000', '711000000001', '711000000002', '711000000003', '711000000004', '712000000000', '712000000001', '712000000002', '712000000003', '712000000004', '713000000000', '713000000001', '713000000002', '713000000003', '713000000004', '714000000000', '714000000001', '714000000002', '714000000003', '714000000004', '721000000000', '721000000001', '721000000002', '721000000003', '721000000004', '722000000000', '722000000001', '722000000002', '722000000003', '722000000004', '723000000000', '723000000001', '723000000002', '723000000003', '723000000004', '724000000000', '724000000001', '724000000002', '724000000003', '724000000004', '811000000000', '811000000001', '811000000002', '811000000003', '811000000004', '811000000005', '811000000006', '811000000007', '811000000008', '811000000009', '812000000000', '812000000001', '812000000002', '812000000003', '812000000004', '812000000005', '812000000006', '812000000007', '812000000008', '812000000009', '813000000000', '813000000001', '813000000002', '813000000003', '813000000004', '813000000005', '813000000006', '813000000007', '813000000008', '813000000009', '814000000000', '814000000001', '814000000002', '814000000003', '814000000004', '814000000005', '814000000006', '814000000007', '814000000008', '814000000009', '821000000000', '821000000001', '821000000002', '821000000003', '821000000004', '821000000005', '821000000006', '821000000007', '821000000008', '821000000009', '822000000000', '822000000001', '822000000002', '822000000003', '822000000004', '822000000005', '822000000006', '822000000007', '822000000008', '822000000009', '823000000000', '823000000001', '823000000002', '823000000003', '823000000004', '823000000005', '823000000006', '823000000007', '823000000008', '823000000009', '824000000000', '824000000001', '824000000002', '824000000003', '824000000004', '824000000005', '824000000006', '824000000007', '824000000008', '824000000009', '911000000000', '911000000001', '911000000002', '911000000003', '911000000004', '911000000005', '911000000006', '911000000007', '911000000008', '911000000009', '912000000000', '912000000001', '912000000002', '912000000003', '912000000004', '912000000005', '912000000006', '912000000007', '912000000008', '912000000009', '913000000000', '913000000001', '913000000002', '913000000003', '913000000004', '913000000005', '913000000006', '913000000007', '913000000008', '913000000009', '914000000000', '914000000001', '914000000002', '914000000003', '914000000004', '914000000005', '914000000006', '914000000007', '914000000008', '914000000009', '921000000000', '921000000001', '921000000002', '921000000003', '921000000004', '921000000005', '921000000006', '921000000007', '921000000008', '921000000009', '922000000000', '922000000001', '922000000002', '922000000003', '922000000004', '922000000005', '922000000006', '922000000007', '922000000008', '922000000009', '923000000000', '923000000001', '923000000002', '923000000003', '923000000004', '923000000005', '923000000006', '923000000007', '923000000008', '923000000009', '924000000000', '924000000001', '924000000002', '924000000003', '924000000004', '924000000005', '924000000006', '924000000007', '924000000008', '924000000009']\n",
      "['image_path', 'original_prompt', 'editing_prompt', 'editing_instruction', 'editing_type_id', 'blended_word', 'mask']\n",
      "{'image_path': '0_random_140/000000000001.jpg', 'original_prompt': 'a [round] cake with orange frosting on a wooden plate', 'editing_prompt': 'a [square] cake with orange frosting on a wooden plate', 'editing_instruction': 'Change the cake shape to square', 'editing_type_id': '0', 'blended_word': 'cake cake', 'mask': [0, 513, 1023, 2, 1535, 2, 2047, 2, 2559, 2, 3071, 2, 3583, 2, 4095, 2, 4607, 2, 5119, 2, 5631, 2, 6143, 2, 6655, 2, 7167, 2, 7679, 2, 8191, 2, 8703, 2, 9215, 2, 9727, 2, 10239, 2, 10751, 2, 11263, 2, 11775, 2, 12287, 2, 12799, 2, 13311, 2, 13823, 2, 14335, 2, 14847, 2, 15359, 2, 15871, 2, 16383, 2, 16895, 2, 17407, 2, 17919, 2, 18431, 2, 18943, 2, 19455, 2, 19967, 2, 20479, 2, 20991, 2, 21503, 2, 22015, 2, 22527, 2, 23039, 2, 23551, 2, 24063, 2, 24575, 2, 25087, 2, 25599, 2, 26111, 2, 26623, 2, 27135, 2, 27647, 2, 28159, 2, 28671, 2, 29183, 2, 29695, 2, 30207, 2, 30719, 2, 31231, 2, 31743, 2, 32255, 2, 32767, 2, 33279, 2, 33791, 2, 34303, 2, 34815, 2, 35327, 2, 35839, 2, 36351, 2, 36863, 2, 37375, 2, 37887, 2, 38399, 2, 38911, 2, 39423, 2, 39935, 2, 40447, 2, 40959, 2, 41471, 2, 41983, 2, 42495, 2, 43007, 2, 43519, 2, 44031, 2, 44543, 2, 45055, 2, 45567, 2, 46079, 2, 46591, 2, 47103, 2, 47615, 2, 48127, 2, 48639, 2, 49151, 2, 49663, 2, 50175, 2, 50687, 2, 51199, 2, 51711, 2, 52223, 2, 52735, 2, 53247, 2, 53759, 2, 54271, 2, 54783, 2, 55295, 2, 55807, 2, 56319, 2, 56831, 2, 57343, 2, 57855, 2, 58367, 2, 58879, 2, 59391, 2, 59903, 2, 60415, 2, 60927, 2, 61439, 2, 61951, 2, 62463, 2, 62975, 2, 63487, 2, 63999, 2, 64511, 2, 65023, 2, 65535, 2, 66047, 2, 66257, 15, 66274, 24, 66302, 18, 66333, 10, 66559, 2, 66763, 97, 67071, 2, 67270, 116, 67583, 2, 67764, 5, 67773, 128, 68095, 2, 68272, 144, 68607, 2, 68781, 155, 69119, 2, 69288, 169, 69631, 2, 69795, 178, 70143, 2, 70304, 187, 70655, 2, 70813, 193, 71167, 2, 71322, 200, 71679, 2, 71831, 205, 72191, 2, 72340, 210, 72703, 2, 72848, 217, 73215, 2, 73358, 222, 73727, 2, 73867, 228, 74239, 2, 74377, 233, 74751, 2, 74886, 239, 75263, 2, 75396, 244, 75775, 2, 75905, 253, 76287, 2, 76414, 261, 76799, 2, 76923, 271, 77311, 2, 77431, 280, 77823, 2, 77941, 284, 78335, 2, 78451, 288, 78847, 2, 78962, 293, 79359, 2, 79472, 298, 79871, 2, 79981, 304, 80383, 2, 80491, 308, 80895, 2, 81001, 312, 81407, 2, 81511, 315, 81919, 2, 82021, 319, 82431, 2, 82532, 321, 82943, 2, 83042, 324, 83455, 2, 83553, 326, 83967, 2, 84064, 328, 84479, 2, 84575, 330, 84991, 2, 85085, 333, 85503, 2, 85596, 335, 86015, 2, 86107, 337, 86527, 2, 86618, 339, 87039, 2, 87129, 341, 87551, 2, 87640, 343, 88063, 2, 88152, 344, 88575, 2, 88663, 346, 89087, 2, 89174, 347, 89599, 2, 89686, 348, 90111, 2, 90197, 349, 90623, 2, 90709, 349, 91135, 2, 91220, 351, 91647, 2, 91732, 351, 92159, 2, 92244, 351, 92671, 2, 92755, 353, 93183, 2, 93267, 353, 93695, 2, 93778, 354, 94207, 2, 94290, 354, 94719, 2, 94802, 354, 95231, 2, 95314, 354, 95743, 2, 95826, 354, 96255, 2, 96337, 355, 96767, 2, 96849, 355, 97279, 2, 97361, 355, 97791, 2, 97872, 356, 98303, 2, 98384, 356, 98815, 2, 98896, 356, 99327, 2, 99408, 356, 99839, 2, 99920, 356, 100351, 2, 100432, 356, 100863, 2, 100944, 356, 101375, 2, 101456, 356, 101887, 2, 101968, 356, 102399, 2, 102480, 356, 102911, 2, 102992, 356, 103423, 2, 103503, 357, 103935, 2, 104015, 357, 104447, 2, 104527, 357, 104959, 2, 105039, 357, 105471, 2, 105551, 357, 105983, 2, 106063, 357, 106495, 2, 106575, 357, 107007, 2, 107087, 357, 107519, 2, 107599, 357, 108031, 2, 108111, 357, 108543, 2, 108623, 357, 109055, 2, 109135, 357, 109567, 2, 109647, 357, 110079, 2, 110159, 357, 110591, 2, 110671, 357, 111103, 2, 111183, 357, 111615, 2, 111695, 357, 112127, 2, 112207, 357, 112639, 2, 112719, 357, 113151, 2, 113231, 357, 113663, 2, 113743, 357, 114175, 2, 114255, 357, 114687, 2, 114767, 357, 115199, 2, 115279, 357, 115711, 2, 115791, 357, 116223, 2, 116303, 357, 116735, 2, 116815, 357, 117247, 2, 117327, 357, 117759, 2, 117839, 357, 118271, 2, 118351, 357, 118783, 2, 118863, 357, 119295, 2, 119375, 357, 119807, 2, 119887, 357, 120319, 2, 120399, 357, 120831, 2, 120911, 357, 121343, 2, 121423, 357, 121855, 2, 121935, 357, 122367, 2, 122447, 357, 122879, 2, 122959, 357, 123391, 2, 123471, 357, 123903, 2, 123983, 357, 124415, 2, 124495, 357, 124927, 2, 125007, 357, 125439, 2, 125519, 357, 125951, 2, 126031, 357, 126463, 2, 126543, 357, 126975, 2, 127055, 357, 127487, 2, 127567, 357, 127999, 2, 128079, 357, 128511, 2, 128591, 357, 129023, 2, 129103, 357, 129535, 2, 129615, 357, 130047, 2, 130127, 357, 130559, 2, 130639, 357, 131071, 2, 131151, 357, 131583, 2, 131663, 357, 132095, 2, 132175, 357, 132607, 2, 132687, 357, 133119, 2, 133199, 357, 133631, 2, 133711, 357, 134143, 2, 134223, 357, 134655, 2, 134735, 357, 135167, 2, 135247, 357, 135679, 2, 135759, 357, 136191, 2, 136271, 357, 136703, 2, 136783, 356, 137215, 2, 137295, 356, 137727, 2, 137807, 356, 138239, 2, 138319, 356, 138751, 2, 138831, 356, 139263, 2, 139343, 356, 139775, 2, 139855, 356, 140287, 2, 140367, 356, 140799, 2, 140879, 356, 141311, 2, 141391, 356, 141823, 2, 141903, 355, 142335, 2, 142415, 355, 142847, 2, 142927, 355, 143359, 2, 143439, 355, 143871, 2, 143951, 355, 144383, 2, 144463, 355, 144895, 2, 144975, 355, 145407, 2, 145487, 355, 145919, 2, 145999, 355, 146431, 2, 146511, 355, 146943, 2, 147023, 355, 147455, 2, 147535, 355, 147967, 2, 148047, 355, 148479, 2, 148559, 355, 148991, 2, 149071, 355, 149503, 2, 149583, 355, 150015, 2, 150095, 355, 150527, 2, 150607, 355, 151039, 2, 151119, 355, 151551, 2, 151631, 355, 152063, 2, 152143, 355, 152575, 2, 152655, 355, 153087, 2, 153167, 355, 153599, 2, 153679, 355, 154111, 2, 154190, 356, 154623, 2, 154702, 356, 155135, 2, 155214, 356, 155647, 2, 155726, 356, 156159, 2, 156238, 356, 156671, 2, 156750, 356, 157183, 2, 157262, 356, 157695, 2, 157774, 356, 158207, 2, 158286, 356, 158719, 2, 158798, 356, 159231, 2, 159310, 356, 159743, 2, 159822, 356, 160255, 2, 160334, 356, 160767, 2, 160846, 356, 161279, 2, 161359, 355, 161791, 2, 161871, 355, 162303, 2, 162383, 355, 162815, 2, 162895, 355, 163327, 2, 163408, 354, 163839, 2, 163920, 354, 164351, 2, 164433, 353, 164863, 2, 164946, 351, 165375, 2, 165458, 351, 165887, 2, 165971, 349, 166399, 2, 166483, 349, 166911, 2, 166995, 349, 167423, 2, 167508, 347, 167935, 2, 168020, 347, 168447, 2, 168532, 346, 168959, 2, 169045, 345, 169471, 2, 169557, 344, 169983, 2, 170070, 343, 170495, 2, 170583, 341, 171007, 2, 171096, 339, 171519, 2, 171609, 338, 172031, 2, 172122, 336, 172543, 2, 172635, 334, 173055, 2, 173148, 332, 173567, 2, 173661, 330, 174079, 2, 174174, 328, 174591, 2, 174687, 326, 175103, 2, 175200, 324, 175615, 2, 175713, 322, 176127, 2, 176227, 319, 176639, 2, 176740, 316, 177151, 2, 177254, 313, 177663, 2, 177767, 311, 178175, 2, 178281, 308, 178687, 2, 178794, 305, 179199, 2, 179308, 302, 179711, 2, 179822, 298, 180223, 2, 180335, 296, 180735, 2, 180849, 292, 181247, 2, 181363, 289, 181759, 2, 181876, 286, 182271, 2, 182390, 282, 182783, 2, 182904, 278, 183295, 2, 183419, 272, 183807, 2, 183933, 268, 184319, 2, 184447, 263, 184831, 2, 184961, 259, 185343, 2, 185475, 255, 185855, 2, 185989, 250, 186367, 2, 186504, 245, 186879, 2, 187018, 241, 187391, 2, 187532, 235, 187903, 2, 188048, 228, 188415, 2, 188563, 221, 188927, 2, 189078, 214, 189439, 2, 189593, 207, 189951, 2, 190110, 198, 190463, 2, 190625, 191, 190975, 2, 191140, 184, 191487, 2, 191656, 176, 191999, 2, 192173, 166, 192511, 2, 192691, 154, 193023, 2, 193208, 143, 193535, 2, 193726, 130, 194047, 2, 194243, 116, 194559, 2, 194760, 102, 195071, 2, 195282, 79, 195583, 2, 196095, 2, 196607, 2, 197119, 2, 197631, 2, 198143, 2, 198655, 2, 199167, 2, 199679, 2, 200191, 2, 200703, 2, 201215, 2, 201727, 2, 202239, 2, 202751, 2, 203263, 2, 203775, 2, 204287, 2, 204799, 2, 205311, 2, 205823, 2, 206335, 2, 206847, 2, 207359, 2, 207871, 2, 208383, 2, 208895, 2, 209407, 2, 209919, 2, 210431, 2, 210943, 2, 211455, 2, 211967, 2, 212479, 2, 212991, 2, 213503, 2, 214015, 2, 214527, 2, 215039, 2, 215551, 2, 216063, 2, 216575, 2, 217087, 2, 217599, 2, 218111, 2, 218623, 2, 219135, 2, 219647, 2, 220159, 2, 220671, 2, 221183, 2, 221695, 2, 222207, 2, 222719, 2, 223231, 2, 223743, 2, 224255, 2, 224767, 2, 225279, 2, 225791, 2, 226303, 2, 226815, 2, 227327, 2, 227839, 2, 228351, 2, 228863, 2, 229375, 2, 229887, 2, 230399, 2, 230911, 2, 231423, 2, 231935, 2, 232447, 2, 232959, 2, 233471, 2, 233983, 2, 234495, 2, 235007, 2, 235519, 2, 236031, 2, 236543, 2, 237055, 2, 237567, 2, 238079, 2, 238591, 2, 239103, 2, 239615, 2, 240127, 2, 240639, 2, 241151, 2, 241663, 2, 242175, 2, 242687, 2, 243199, 2, 243711, 2, 244223, 2, 244735, 2, 245247, 2, 245759, 2, 246271, 2, 246783, 2, 247295, 2, 247807, 2, 248319, 2, 248831, 2, 249343, 2, 249855, 2, 250367, 2, 250879, 2, 251391, 2, 251903, 2, 252415, 2, 252927, 2, 253439, 2, 253951, 2, 254463, 2, 254975, 2, 255487, 2, 255999, 2, 256511, 2, 257023, 2, 257535, 2, 258047, 2, 258559, 2, 259071, 2, 259583, 2, 260095, 2, 260607, 2, 261119, 2, 261631, 513]}\n",
      "defaultdict(<class 'int'>, {'0': 140, '1': 80, '2': 80, '3': 80, '4': 40, '5': 40, '6': 40, '7': 40, '8': 80, '9': 80})\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from collections import defaultdict\n",
    "with open(\"/share/u/wendler/PIE-Bench_v1/mapping_file.json\", \"r\") as f:\n",
    "    pb = json.load(f)\n",
    "print(list(pb.keys()))\n",
    "print(list(pb[\"000000000001\"].keys()))\n",
    "print(pb[\"000000000001\"])\n",
    "\n",
    "cnts = defaultdict(int)\n",
    "for key, val in pb.items():\n",
    "    cnts[val[\"editing_type_id\"]]+=1\n",
    "    #print(val[\"blended_word\"])\n",
    "print(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "blocks_to_intervene = []\n",
    "if use_down:\n",
    "     blocks_to_intervene.append(\"down.2.1\")\n",
    "if use_up:\n",
    "     blocks_to_intervene.append(\"up.0.1\")\n",
    "if use_up0:\n",
    "     blocks_to_intervene.append(\"up.0.0\")\n",
    "if use_mid:\n",
    "     blocks_to_intervene.append(\"mid.0\")\n",
    "\n",
    "\n",
    "for key, val in pb.items():\n",
    "     if True or (int(val[\"editing_type_id\"]) >= 0 and cnts[val[\"editing_type_id\"]] < 10):\n",
    "          try:\n",
    "               if val[\"blended_word\"] == \"\":\n",
    "                    continue\n",
    "               w1 = val[\"blended_word\"].split(\" \")[0]\n",
    "               w2 = val[\"blended_word\"].split(\" \")[1]\n",
    "               os.makedirs(f\"../results/PIE-Bench/{n_steps}_{m1}_{k_transfer}_{use_down}_{use_up}_{use_up0}_{use_mid}/{val['editing_type_id']}\", exist_ok=True)\n",
    "               main(val[\"editing_prompt\"], val[\"original_prompt\"], w2, w1, \n",
    "                    blocks_to_intervene=blocks_to_intervene,\n",
    "                    n_steps=n_steps, m1=m1, k_transfer=k_transfer, stat=\"max\", k=10, mode=\"sae\", \n",
    "                    result_name=f\"../results/PIE-Bench/{n_steps}_{m1}_{k_transfer}_{use_down}_{use_up}_{use_up0}_{use_mid}/{val['editing_type_id']}/{key}\")\n",
    "               cnts[val[\"editing_type_id\"]]+=1\n",
    "          except Exception as e:\n",
    "               print(e)\n",
    "               continue\n",
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdxlsae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
